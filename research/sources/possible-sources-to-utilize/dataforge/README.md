# DataForge

Advanced data transformation and processing plugin for Claude Code that provides powerful querying, filtering, validation, and conversion capabilities for JSON, CSV, XML, YAML, and other data formats.

## Purpose

DataForge solves the common challenge developers face when working with data files: transforming, validating, converting, and analyzing data across different formats. Inspired by powerful CLI tools like `jq`, `csvkit`, and modern data processing utilities, DataForge brings enterprise-grade data manipulation directly into your Claude Code workflow.

## Why DataForge?

**Common Developer Pain Points:**
- "I need to extract specific fields from this huge JSON file"
- "How do I convert this CSV to JSON for my API?"
- "I need to validate this data against a schema before importing"
- "Can I generate TypeScript types from this API response?"
- "I need to filter 10,000 rows by multiple conditions"

**DataForge Makes It Easy:**
- Query and transform data with natural language
- Convert between formats seamlessly
- Validate data quality and schema compliance
- Generate schemas and type definitions automatically
- Process large files efficiently

## Features

### ðŸ” JSON Query & Transformation
- Extract nested fields with jq-style operations
- Filter arrays by complex conditions
- Reshape and restructure data
- Aggregate and compute statistics
- Merge and combine JSON files

### ðŸ“Š CSV Processing
- Filter rows by multiple criteria
- Select and rename columns
- Sort, group, and aggregate data
- Merge multiple CSV files
- Clean and normalize data
- Handle large datasets efficiently

### ðŸ”„ Format Conversion
- **JSON** â†” CSV, YAML, XML, TOML, Excel
- **CSV** â†” JSON, YAML, Excel, Markdown
- **YAML** â†” JSON, TOML
- **XML** â†” JSON
- Smart type preservation during conversion
- Bidirectional transformations

### âœ… Data Validation
- Validate against JSON Schema
- Type checking and format validation
- Detect missing values and duplicates
- Find outliers and anomalies
- Check referential integrity
- Custom business rule validation

### ðŸ—ï¸ Schema Generation
- Generate JSON Schema from data
- Create TypeScript interfaces
- Generate SQL DDL (CREATE TABLE)
- Build Zod/Yup validators
- Create OpenAPI specifications
- GraphQL schema generation

## Installation

First, add the Claude Registry marketplace (if you haven't already):

```bash
/plugin marketplace add clauderegistry/marketplace
```

Then install DataForge:

```bash
/plugin install dataforge
```

Or use the interactive browser:

```bash
/plugin
```

## Commands

Once installed, you can use the following slash commands in any Claude Code session:

### /json-query

Query, filter, and transform JSON data with powerful operations.

```
/json-query
```

**What it does:**
- Extract specific fields from nested JSON
- Filter arrays by conditions
- Navigate complex data structures
- Reshape and transform data
- Aggregate values (sum, count, average)
- Remove null/undefined values
- Pretty-print or minify JSON

**Example usage:**
```
/json-query
â†’ "Extract all user emails from users.json"
â†’ "Get orders where total > 100 from orders.json"
â†’ "Flatten the nested products array"
â†’ "Group sales by category and sum amounts"
```

**Common operations:**
- Extract fields: `users.map(u => u.email)`
- Filter data: `users.filter(u => u.age > 18)`
- Nested navigation: `orders.flatMap(o => o.items)`
- Aggregation: `sales.reduce((sum, s) => sum + s.amount)`

### /csv-transform

Process CSV/TSV files with filtering, sorting, and transformation.

```
/csv-transform
```

**What it does:**
- Select specific columns
- Filter rows by conditions
- Sort by single or multiple columns
- Group and aggregate data
- Merge multiple CSV files
- Clean and normalize data
- Handle missing values
- Convert delimiters (CSV â†” TSV)

**Example usage:**
```
/csv-transform
â†’ "Get all rows where age > 18 from users.csv"
â†’ "Select only name, email, and score columns"
â†’ "Sort by score descending"
â†’ "Calculate average revenue by category"
â†’ "Merge customers.csv and orders.csv on customer_id"
```

**Best for:**
- Data cleaning and preprocessing
- Filtering large datasets
- Preparing data for import
- Combining multiple data sources
- Quick data exploration

### /format-converter

Convert between different data formats seamlessly.

```
/format-converter
```

**What it does:**
- Convert JSON to CSV, YAML, XML, TOML, Excel
- Convert CSV to JSON, YAML, Excel, Markdown
- Convert YAML to JSON, TOML
- Convert XML to JSON
- Convert Excel to CSV, JSON
- Preserve data types during conversion
- Handle nested structures intelligently

**Example usage:**
```
/format-converter
â†’ "Convert users.json to CSV"
â†’ "Convert config.yaml to JSON"
â†’ "Convert sales.csv to Excel with formatting"
â†’ "Convert API response XML to JSON"
â†’ "Convert data.json to YAML with comments"
```

**Supported formats:**
- JSON (standard, JSONL)
- CSV/TSV
- YAML
- XML
- TOML
- Excel (XLSX)
- Markdown tables

**Smart features:**
- Flattens nested JSON for CSV export
- Infers types when converting to JSON
- Preserves arrays and objects
- Handles special characters and escaping

### /data-validator

Validate data files against schemas and quality rules.

```
/data-validator
```

**What it does:**
- Validate JSON against JSON Schema
- Check CSV column types and constraints
- Detect missing/null values
- Find duplicate records
- Identify outliers and anomalies
- Validate business rules
- Check referential integrity
- Generate validation reports

**Example usage:**
```
/data-validator
â†’ "Validate users.json against schema.json"
â†’ "Check if customers.csv is ready for database import"
â†’ "Find duplicate email addresses in users.csv"
â†’ "Detect outliers in sales data"
â†’ "Validate that all order IDs exist in orders table"
```

**Validation types:**
- **Schema validation**: JSON Schema compliance
- **Type checking**: Ensure correct data types
- **Format validation**: Email, URL, date formats
- **Range validation**: Min/max values
- **Required fields**: Check for missing data
- **Duplicates**: Find duplicate records
- **Outliers**: Statistical anomaly detection
- **Business rules**: Custom validation logic

**Report includes:**
- Error count by severity
- Detailed error messages with row numbers
- Data quality metrics
- Missing value analysis
- Format inconsistencies
- Actionable suggestions for fixes

### /schema-generator

Generate schemas and type definitions from data files.

```
/schema-generator
```

**What it does:**
- Generate JSON Schema from JSON data
- Create TypeScript interfaces
- Generate SQL DDL (CREATE TABLE statements)
- Build Zod validators for runtime validation
- Create Yup schemas
- Generate OpenAPI/Swagger specifications
- Infer types from multiple records

**Example usage:**
```
/schema-generator
â†’ "Generate TypeScript interface from users.json"
â†’ "Create SQL schema from customers.csv"
â†’ "Generate JSON Schema from API response"
â†’ "Create Zod validator from data.json"
â†’ "Generate OpenAPI spec from API examples"
```

**Smart inference:**
- Analyzes multiple records for accuracy
- Detects optional vs required fields
- Infers formats (email, URL, date)
- Determines min/max constraints
- Identifies enum values
- Suggests validation rules

**Output formats:**
- JSON Schema (draft-07)
- TypeScript interfaces
- SQL DDL (PostgreSQL, MySQL)
- Zod schemas
- Yup schemas
- OpenAPI 3.0 specs
- GraphQL schemas

## Typical Workflows

### Workflow 1: API Integration
**Scenario**: Working with a new API and need to understand and type the data

```
1. Fetch API response and save to response.json
2. /json-query â†’ Explore structure and extract needed fields
3. /schema-generator â†’ Generate TypeScript interfaces
4. /data-validator â†’ Create validation schema
5. Use generated types in your application
```

### Workflow 2: Data Import Preparation
**Scenario**: Preparing CSV data for database import

```
1. /csv-transform â†’ Clean and filter data
2. /data-validator â†’ Check data quality and find issues
3. /csv-transform â†’ Fix identified issues
4. /schema-generator â†’ Generate CREATE TABLE statement
5. /format-converter â†’ Convert to SQL INSERT statements
6. Import to database
```

### Workflow 3: Data Migration
**Scenario**: Migrating data between systems

```
1. Export from source system (CSV/JSON)
2. /data-validator â†’ Validate source data
3. /format-converter â†’ Convert to target format
4. /csv-transform â†’ Transform to match target schema
5. /data-validator â†’ Validate transformed data
6. Import to target system
```

### Workflow 4: Configuration Management
**Scenario**: Converting and validating configuration files

```
1. /format-converter â†’ Convert YAML config to JSON
2. /schema-generator â†’ Generate JSON Schema
3. /data-validator â†’ Validate all environment configs
4. /format-converter â†’ Convert back to YAML if needed
```

### Workflow 5: Data Analysis
**Scenario**: Quick analysis of CSV/JSON data

```
1. /json-query or /csv-transform â†’ Filter to relevant subset
2. /csv-transform â†’ Group and aggregate by dimensions
3. /format-converter â†’ Convert to Excel for stakeholders
4. /data-validator â†’ Check for data quality issues
```

## Real-World Use Cases

### Use Case 1: "Extract User Emails from Nested JSON"
**Problem**: API returns deeply nested user objects, need just emails.

**Solution**:
```
/json-query
â†’ "Extract all user emails from api-response.json"

Result: Clean array of email addresses ready to use
```

---

### Use Case 2: "CSV Data Cleaning Before Import"
**Problem**: CSV has duplicates, missing values, wrong types.

**Solution**:
```
/data-validator
â†’ Check data quality, find issues

/csv-transform
â†’ Remove duplicates, fill missing values, fix types

/data-validator
â†’ Verify data is clean

/format-converter
â†’ Convert to JSON for API import
```

---

### Use Case 3: "Generate Types from API Response"
**Problem**: Need TypeScript types for new API endpoint.

**Solution**:
```
/schema-generator
â†’ "Generate TypeScript interface from response.json"

Result: Complete, accurate TypeScript interface ready to use
```

---

### Use Case 4: "Merge Customer and Order Data"
**Problem**: Need to join two CSV files for analysis.

**Solution**:
```
/csv-transform
â†’ "Merge customers.csv and orders.csv on customer_id"

Result: Combined dataset with customer info and orders
```

---

### Use Case 5: "Convert Excel to JSON API Format"
**Problem**: Business team provides Excel, need JSON for API.

**Solution**:
```
/format-converter
â†’ "Convert products.xlsx to JSON"

/json-query
â†’ Reshape to match API structure

/data-validator
â†’ Validate against API schema
```

## What Makes DataForge Different

### vs. Manual Processing
- **Manual**: Write custom scripts for each transformation
- **DataForge**: Natural language commands, instant results

### vs. jq/csvkit
- **CLI Tools**: Requires learning complex syntax
- **DataForge**: Conversational interface, more accessible

### vs. Excel/Google Sheets
- **Spreadsheets**: Manual point-and-click, limited automation
- **DataForge**: Scriptable, reproducible, handles larger files

### vs. Python Pandas
- **Pandas**: Write code, set up environment, debug
- **DataForge**: Describe what you want, get results immediately

### vs. Online Converters
- **Online Tools**: Upload sensitive data, limited features
- **DataForge**: Local processing, comprehensive capabilities

## Performance & Limits

### File Size Handling
- **Small files** (<1MB): Instant processing
- **Medium files** (1-100MB): Efficient in-memory processing
- **Large files** (>100MB): Streaming support for CSV/JSON
- **Very large files** (>1GB): Chunked processing with progress

### Best Practices
- For very large JSON files, use /json-query to filter first
- CSV files with millions of rows process via streaming
- Large transformations auto-save intermediate results
- Memory usage warnings for files >500MB

## Plugin Structure

```
dataforge/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json              # Plugin manifest
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ json-query.md            # JSON transformation
â”‚   â”œâ”€â”€ csv-transform.md         # CSV processing
â”‚   â”œâ”€â”€ format-converter.md      # Format conversion
â”‚   â”œâ”€â”€ data-validator.md        # Data validation
â”‚   â””â”€â”€ schema-generator.md      # Schema generation
â””â”€â”€ README.md                     # This file
```

## Requirements

- Claude Code CLI installed
- Claude Code version compatible with plugins feature
- Node.js recommended for optimal performance (auto-detected)

## Supported Data Formats

| Format | Read | Write | Query | Validate | Convert From | Convert To |
|--------|------|-------|-------|----------|--------------|------------|
| JSON   | âœ“    | âœ“     | âœ“     | âœ“        | All          | All        |
| CSV    | âœ“    | âœ“     | âœ“     | âœ“        | JSON, Excel  | All        |
| YAML   | âœ“    | âœ“     | âœ“     | âœ“        | JSON, TOML   | JSON, TOML |
| XML    | âœ“    | âœ“     | âœ—     | âœ“        | JSON         | JSON       |
| TOML   | âœ“    | âœ“     | âœ—     | âœ“        | JSON, YAML   | JSON, YAML |
| Excel  | âœ“    | âœ“     | âœ—     | âœ—        | CSV, JSON    | CSV, JSON  |
| JSONL  | âœ“    | âœ“     | âœ“     | âœ“        | JSON         | JSON       |

## Common Questions

### "Can I process multiple files at once?"
Yes! Commands can process multiple files, merge them, or batch convert.

### "Does it handle large files?"
Yes, files up to several GB are supported via streaming for CSV/JSONL.

### "Is my data sent anywhere?"
No, all processing happens locally in your environment.

### "Can I automate repetitive transformations?"
Yes, all commands are scriptable and can be chained together.

### "What if I don't know the data structure?"
Use /json-query or /csv-transform to explore and preview first.

### "Can it handle malformed data?"
Yes, validation reports issues and suggests fixes.

## Tips & Tricks

### Quick Exploration
```
/json-query â†’ "Show me the structure of data.json"
/csv-transform â†’ "Preview first 10 rows of data.csv"
```

### Chaining Operations
```
/json-query â†’ Extract and filter
/data-validator â†’ Check quality
/format-converter â†’ Convert to needed format
```

### Type Safety Workflow
```
/schema-generator â†’ Generate TypeScript types
/data-validator â†’ Create runtime validator
Use both in your application
```

### Migration Checklist
```
1. /data-validator â†’ Validate source
2. /format-converter â†’ Convert format
3. /csv-transform â†’ Transform structure
4. /data-validator â†’ Validate target
5. Import
```

## Managing the Plugin

To disable the plugin temporarily:
```bash
/plugin disable dataforge
```

To enable it again:
```bash
/plugin enable dataforge
```

To uninstall completely:
```bash
/plugin uninstall dataforge
```

## Contributing

Contributions are welcome! To improve DataForge:

1. Fork the repository
2. Create a feature branch
3. Make your changes to command files in `commands/`
4. Test with various data formats and sizes
5. Submit a pull request

### Ideas for Contributions:
- Add new data format support (Parquet, Avro, Protocol Buffers)
- Enhance validation rules
- Add more transformation patterns
- Improve performance for large files
- Add visualization capabilities

## License

MIT

## Version

1.0.0

## Acknowledgments

Inspired by powerful CLI data tools:
- **jq** - JSON query and transformation
- **csvkit** - CSV processing suite
- **yq** - YAML/XML query tool
- **miller** - Name-indexed data processing

Built for developers who work with data every day and need fast, reliable transformations without leaving their development environment.

---

**Stop wrestling with data formats. Let DataForge handle it.**

Made with precision for the Claude Code community ðŸ”§
