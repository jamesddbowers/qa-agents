---
name: test-tagging
description: Define and apply test categorization conventions for smoke and regression testing. Use when you need to tag API tests, define smoke test criteria, categorize regression tests, organize test suites by priority, create test tiers for CI/CD, or support QA MVP Step 4. Provides tagging standards for Postman collections and Newman execution.
---

# Test Tagging

Define test categorization conventions for organizing smoke and regression test suites.

## Quick Start

1. Define tag taxonomy
2. Establish categorization criteria
3. Apply tags to requests
4. Configure Newman filtering

## Standard Tag Taxonomy

| Tag | Purpose | Run Frequency | Max Duration |
|-----|---------|---------------|--------------|
| `smoke` | Critical path validation | Every deployment | < 2 min |
| `regression` | Comprehensive coverage | Nightly/Weekly | < 30 min |
| `critical` | Business-critical, alert on failure | Every deployment | N/A |
| `performance` | Include response time assertions | With regression | N/A |
| `wip` | Work in progress, skip in CI | Never in CI | N/A |

## Categorization Criteria

### Smoke Test Criteria

Include in smoke tests if ANY of:
- Top 20% by traffic volume
- Authentication/authorization endpoints
- Critical business transactions (checkout, payment)
- Health check endpoints
- Core CRUD operations for primary entities

### Regression Test Criteria

Include in regression tests if ANY of:
- All smoke tests (superset)
- Complete CRUD coverage for all entities
- Edge cases and error scenarios
- Validation and input handling
- Less frequent but important workflows

### Tag Decision Tree

```
Is this endpoint critical to business?
â”œâ”€ YES â†’ smoke, critical
â””â”€ NO
   Is this a high-traffic endpoint (top 20%)?
   â”œâ”€ YES â†’ smoke
   â””â”€ NO
      Is this endpoint tested elsewhere?
      â”œâ”€ YES (covered by smoke) â†’ regression
      â””â”€ NO â†’ regression
         Is this work in progress?
         â”œâ”€ YES â†’ wip
         â””â”€ NO â†’ regression
```

## Postman Tagging

### Folder-Based Organization

```
Collection
â”œâ”€â”€ ðŸ“ Auth [smoke, critical]
â”‚   â”œâ”€â”€ Login
â”‚   â””â”€â”€ Token Refresh
â”œâ”€â”€ ðŸ“ Users
â”‚   â”œâ”€â”€ ðŸ“ smoke
â”‚   â”‚   â”œâ”€â”€ GET List Users
â”‚   â”‚   â””â”€â”€ POST Create User
â”‚   â””â”€â”€ ðŸ“ regression
â”‚       â”œâ”€â”€ GET User by ID
â”‚       â”œâ”€â”€ PUT Update User
â”‚       â””â”€â”€ DELETE User
â””â”€â”€ ðŸ“ Orders [smoke, critical]
    â”œâ”€â”€ GET List Orders
    â””â”€â”€ POST Create Order
```

### Request-Level Tags

In request description or name:
```
GET List Users [smoke]
POST Create Order [smoke, critical]
DELETE User [regression]
```

## Newman Filtering

### By Folder Name

```bash
# Run smoke tests only
newman run collection.json --folder "smoke"

# Run specific resource folder
newman run collection.json --folder "Users"
```

### By Collection Tag (Custom Implementation)

Pre-request script to skip non-matching tags:
```javascript
const requiredTag = pm.environment.get('TEST_TAG') || 'smoke';
const requestTags = pm.info.requestName.match(/\[(.*?)\]/);

if (requestTags && !requestTags[1].includes(requiredTag)) {
    pm.execution.skipRequest();
}
```

## Tagging Best Practices

1. **Consistent naming**: Use lowercase tags
2. **Folder structure**: Mirror tag hierarchy
3. **Document criteria**: Explain why tests are tagged
4. **Review regularly**: Update tags as traffic patterns change
5. **Minimal smoke**: Keep smoke tests fast (< 2 min total)

## Output Format

When categorizing tests, generate:

```markdown
## Test Tagging Summary

### Smoke Tests ([count])
- [ ] GET /api/users [smoke]
- [ ] POST /api/orders [smoke, critical]

### Regression Tests ([count])
- [ ] PUT /api/users/{id} [regression]
- [ ] DELETE /api/users/{id} [regression]

### Tagging Rationale
| Endpoint | Tag | Reason |
|----------|-----|--------|
| GET /api/users | smoke | High traffic (1.2M/week) |
| POST /api/orders | smoke, critical | Revenue-critical |
```

See `references/tagging-conventions.md` for detailed conventions.
